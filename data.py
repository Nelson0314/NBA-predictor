import os
import time
import random
import pandas as pd
from tqdm import tqdm
from requests.exceptions import ReadTimeout, ConnectTimeout
import urllib3
from nba_api.stats.static import players
from nba_api.stats.endpoints import playergamelog, shotchartdetail, leaguedashplayerstats, playergamelogs

# ==========================================
# 1. è¨­å®š
# ==========================================
SEASONS = ['2019-20', '2020-21', '2021-22', '2022-23', '2023-24']
TOP_N_PLAYERS = 150
DATASET_DIR = 'dataset'

if not os.path.exists(DATASET_DIR):
    os.makedirs(DATASET_DIR)

GAMES_CSV_PATH = os.path.join(DATASET_DIR, 'games.csv')
SHOTS_CSV_PATH = os.path.join(DATASET_DIR, 'shots.csv')

# ==========================================
# 2. è¼”åŠ©å‡½å¼
# ==========================================
def fetch_with_retry(api_func, max_retries=3, **kwargs):
    kwargs['timeout'] = 25
    for i in range(max_retries):
        try:
            time.sleep(random.uniform(1.5, 3.0)) 
            return api_func(**kwargs)
        except (ReadTimeout, ConnectTimeout, urllib3.exceptions.ReadTimeoutError, ConnectionResetError):
            time.sleep(10)
        except Exception:
            break
    return None

def get_top_scorers(season, top_n=100):
    try:
        stats = leaguedashplayerstats.LeagueDashPlayerStats(season=season, per_mode_detailed='PerGame', timeout=30)
        df = stats.get_data_frames()[0]
        return df.sort_values(by='PTS', ascending=False).head(top_n)[['PLAYER_ID', 'PLAYER_NAME']].to_dict('records')
    except: return []

# ç”¨ä¾†æ¸…ç†é‡è¤‡è³‡æ–™çš„å‡½å¼
def clean_duplicates(filepath, subset_cols):
    if os.path.exists(filepath):
        print(f"ğŸ§¹ æ­£åœ¨æ¸…ç†é‡è¤‡è³‡æ–™: {filepath} ...", end='\r')
        df = pd.read_csv(filepath)
        original_len = len(df)
        # é‡å°ç‰¹å®šæ¬„ä½å»é‡ (ä¿ç•™æœ€å¾Œä¸€ç­†)
        df = df.drop_duplicates(subset=subset_cols, keep='last')
        df.to_csv(filepath, index=False)
        print(f"âœ… æ¸…ç†å®Œæˆ: {filepath} (ç§»é™¤ {original_len - len(df)} ç­†é‡è¤‡)")

# ==========================================
# 3. æº–å‚™ä»»å‹™èˆ‡æª¢æŸ¥çºŒå‚³
# ==========================================
print("æ­¥é©Ÿ 1/3: å»ºç«‹çƒå“¡åå–®...")
target_player_ids = {} 
for season in SEASONS:
    for p in get_top_scorers(season, TOP_N_PLAYERS):
        target_player_ids[p['PLAYER_ID']] = p['PLAYER_NAME']

# å»ºç«‹æ‰€æœ‰ä»»å‹™åˆ—è¡¨
all_tasks = []
for pid, pname in target_player_ids.items():
    for season in SEASONS:
        all_tasks.append((pid, pname, season))

# --- ğŸŸ¢ é—œéµæ”¹è‰¯ï¼šåš´æ ¼çš„çºŒå‚³æª¢æŸ¥ ---
processed_tasks = set()
if os.path.exists(GAMES_CSV_PATH):
    try:
        # å¼·åˆ¶å°‡ Player_ID è®€å–ç‚º stringï¼Œé¿å… int/str æ··æ·†
        existing_df = pd.read_csv(GAMES_CSV_PATH, dtype={'Player_ID': str, 'Season': str})
        
        # å»ºç«‹å·²å®Œæˆçš„ (ID, Season) é›†åˆ
        for _, row in existing_df.iterrows():
            processed_tasks.add((str(row['Player_ID']), str(row['Season'])))
            
        print(f"ğŸ”„ è®€å–èˆŠæª”æˆåŠŸï¼Œå·²å®Œæˆ {len(processed_tasks)} å€‹ä»»å‹™ã€‚")
    except Exception as e: 
        print(f"âš ï¸ è®€å–èˆŠæª”å¤±æ•— (å¯èƒ½æ˜¯ç©ºæª”): {e}")

# éæ¿¾ä»»å‹™ (ç¢ºä¿æ¯”å°æ™‚ä¹Ÿè½‰æˆ string)
tasks_to_run = [
    t for t in all_tasks 
    if (str(t[0]), str(t[2])) not in processed_tasks
]
print(f"ğŸš€ ç¸½ä»»å‹™: {len(all_tasks)} | å‰©é¤˜ä»»å‹™: {len(tasks_to_run)}")

# ==========================================
# 4. åŸ·è¡Œçˆ¬èŸ²
# ==========================================

if not tasks_to_run:
    print("æ‰€æœ‰ä»»å‹™å·²å®Œæˆï¼è·³è‡³æ¸…ç†æ­¥é©Ÿã€‚")
else:
    with tqdm(total=len(tasks_to_run), desc="åˆå§‹åŒ–ä¸­", dynamic_ncols=True, unit="task") as pbar:
        
        for pid, pname, season in tasks_to_run:
            pbar.set_description(f"æ­£åœ¨æŠ“å–: {pname} ({season})")
            
            # --- é›™é‡æª¢æŸ¥ï¼šé˜²æ­¢åœ¨æœ¬æ¬¡åŸ·è¡ŒæœŸé–“é‡è¤‡ ---
            # (é›–ç„¶ tasks_to_run å·²ç¶“æ¿¾éäº†ï¼Œä½†é€™æ˜¯ä¿éšª)
            if (str(pid), str(season)) in processed_tasks:
                pbar.update(1)
                continue

            batch_games = []
            batch_shots = []

            # --- A. åŸºç¤æ•¸æ“š ---
            base_api = fetch_with_retry(playergamelog.PlayerGameLog, player_id=pid, season=season)
            if not base_api: 
                pbar.update(1); continue
            df_base = base_api.get_data_frames()[0]
            if df_base.empty: 
                pbar.update(1); continue

            # --- B. é€²éšæ•¸æ“š ---
            adv_api = fetch_with_retry(
                playergamelogs.PlayerGameLogs, 
                player_id_nullable=pid, season_nullable=season,
                measure_type_player_game_logs_nullable='Advanced'
            )
            df_merged = df_base
            if adv_api:
                df_adv = adv_api.get_data_frames()[0]
                if not df_adv.empty:
                    df_base['Game_ID'] = df_base['Game_ID'].astype(str)
                    df_adv['GAME_ID'] = df_adv['GAME_ID'].astype(str)
                    adv_cols = ['GAME_ID', 'OFF_RATING', 'DEF_RATING', 'NET_RATING', 'AST_PCT', 'AST_TO', 
                                'OREB_PCT', 'TM_TOV_PCT', 'EFG_PCT', 'TS_PCT', 'USG_PCT', 'PACE', 'PIE']
                    valid_cols = [c for c in adv_cols if c in df_adv.columns]
                    df_merged = pd.merge(df_base, df_adv[valid_cols], left_on='Game_ID', right_on='GAME_ID', how='left')

            # --- C. æ•´ç† ---
            try: df_merged['GAME_DATE'] = pd.to_datetime(df_merged['GAME_DATE'])
            except: pass
            df_merged = df_merged.sort_values('GAME_DATE').reset_index(drop=True)
            df_merged['TARGET_PTS'] = df_merged['PTS'].shift(-1)
            df_merged['Player_ID'] = pid
            df_merged['Player_Name'] = pname
            df_merged['Season'] = season
            df_merged = df_merged.dropna(subset=['TARGET_PTS'])
            batch_games.append(df_merged)

            # --- D. æŠ•ç±ƒåœ– ---
            shot_api = fetch_with_retry(
                shotchartdetail.ShotChartDetail,
                team_id=0, player_id=pid, 
                context_measure_simple='FGA', season_nullable=season
            )
            if shot_api:
                df_shots = shot_api.get_data_frames()[0]
                if not df_shots.empty:
                    s_cols = ['GAME_ID', 'LOC_X', 'LOC_Y', 'SHOT_MADE_FLAG', 'SHOT_TYPE', 'ACTION_TYPE']
                    valid = [c for c in s_cols if c in df_shots.columns]
                    batch_shots.append(df_shots[valid])

            # --- E. å­˜æª” ---
            if batch_games:
                df_g = pd.concat(batch_games, ignore_index=True)
                df_g.to_csv(GAMES_CSV_PATH, mode='a', header=not os.path.exists(GAMES_CSV_PATH), index=False)
            
            if batch_shots:
                df_s = pd.concat(batch_shots, ignore_index=True)
                df_s.to_csv(SHOTS_CSV_PATH, mode='a', header=not os.path.exists(SHOTS_CSV_PATH), index=False)

            # æ›´æ–°ç‹€æ…‹èˆ‡é€²åº¦æ¢
            processed_tasks.add((str(pid), str(season)))
            pbar.update(1)

# ==========================================
# 5. æ”¶å°¾ï¼šè³‡æ–™å»é‡æ¸…ç† (Final Cleanup)
# ==========================================
print("\næ­¥é©Ÿ 3/3: æ­£åœ¨é€²è¡Œæœ€çµ‚è³‡æ–™åº«å»é‡èˆ‡æ¸…ç†...")

# é‡å° Games è¡¨ï¼Œå¦‚æœæœ‰é‡è¤‡çš„ (Player_ID, Game_ID)ï¼Œåªç•™ä¸€ç­†
clean_duplicates(GAMES_CSV_PATH, subset_cols=['Player_ID', 'Game_ID'])

# é‡å° Shots è¡¨ï¼Œå¦‚æœæœ‰é‡è¤‡çš„ (GAME_ID, EVENT_ID æˆ–åº§æ¨™)ï¼Œé€™æ¯”è¼ƒé›£åˆ¤æ–·ï¼Œé€šå¸¸ç”¨ GAME_ID + LOC_X + LOC_Y 
# ä½†æœ€ç°¡å–®æ˜¯å»æ‰å®Œå…¨é‡è¤‡çš„è¡Œ
clean_duplicates(SHOTS_CSV_PATH, subset_cols=None) # None ä»£è¡¨æª¢æŸ¥æ‰€æœ‰æ¬„ä½æ˜¯å¦å®Œå…¨ä¸€æ¨£

print("\nğŸ‰ å…¨éƒ¨ä½œæ¥­å®Œæˆï¼è³‡æ–™åº«å·²ä¿è­‰ä¹¾æ·¨ç„¡é‡è¤‡ã€‚")