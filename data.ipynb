{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "a3049e29",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import time\n",
                "import random\n",
                "import pandas as pd\n",
                "from tqdm.notebook import tqdm\n",
                "from requests.exceptions import ReadTimeout, ConnectTimeout\n",
                "import urllib3\n",
                "from nba_api.stats.static import players\n",
                "from nba_api.stats.endpoints import playergamelog, shotchartdetail, leaguedashplayerstats, playergamelogs\n",
                "\n",
                "# ==========================================\n",
                "# 1. Environment & Parameters Setup\n",
                "# ==========================================\n",
                "seasons = ['2016-17', '2017-18', '2018-19', '2019-20', '2020-21', '2021-22', '2022-23', '2023-24', '2024-25']\n",
                "topNPlayers = 150  # Top N scorers per season\n",
                "datasetDir = 'dataset'\n",
                "\n",
                "# Create Directory\n",
                "if not os.path.exists(datasetDir):\n",
                "    os.makedirs(datasetDir)\n",
                "\n",
                "gamesCsvPath = os.path.join(datasetDir, 'games.csv')\n",
                "shotsCsvPath = os.path.join(datasetDir, 'shots.csv')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "b69be571",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ==========================================\n",
                "# 2. Helper Functions\n",
                "# ==========================================\n",
                "\n",
                "def fetchWithRetry(apiFunc, maxRetries=3, **kwargs):\n",
                "    \"\"\"API Request Wrapper: Includes timeout and random retry delay\"\"\"\n",
                "    kwargs['timeout'] = 25\n",
                "    for i in range(maxRetries):\n",
                "        try:\n",
                "            time.sleep(random.uniform(0.3, 0.6)) \n",
                "            return apiFunc(**kwargs)\n",
                "        except (ReadTimeout, ConnectTimeout, urllib3.exceptions.ReadTimeoutError, ConnectionResetError):\n",
                "            time.sleep(5) # Wait longer on error\n",
                "        except Exception:\n",
                "            break\n",
                "    return None\n",
                "\n",
                "def getTopScorers(season, topN=100):\n",
                "    \"\"\"Get Top N Scorers for the season\"\"\"\n",
                "    try:\n",
                "        stats = leaguedashplayerstats.LeagueDashPlayerStats(season=season, per_mode_detailed='PerGame', timeout=30)\n",
                "        df = stats.get_data_frames()[0]\n",
                "        return df.sort_values(by='PTS', ascending=False).head(topN)[['PLAYER_ID', 'PLAYER_NAME']].to_dict('records')\n",
                "    except: return []\n",
                "\n",
                "def cleanDuplicates(filepath, subsetCols):\n",
                "    \"\"\"Data Deduplication Tool\"\"\"\n",
                "    if os.path.exists(filepath):\n",
                "        print(f\"üßπ Cleaning duplicates: {filepath} ...\", end='\\r')\n",
                "        # Use low_memory=False to avoid Dtype warnings\n",
                "        df = pd.read_csv(filepath, low_memory=False)\n",
                "        df = df.drop_duplicates(subset=subsetCols, keep='last')\n",
                "        df.to_csv(filepath, index=False)\n",
                "        print(f\"‚úÖ Cleanup Complete: {filepath}        \")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "c87152d2",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Step 1/3: Building and filtering task list...\n",
                        "üîÑ Locked 1891 completed tasks (Skipping automatically)\n",
                        "üöÄ Total Tasks: 0 | Pending: 0\n"
                    ]
                }
            ],
            "source": [
                "# ==========================================\n",
                "# 3. Prepare Tasks & Check Resume\n",
                "# ==========================================\n",
                "print(\"Step 1/3: Building and filtering task list...\")\n",
                "\n",
                "# A. Create All Target Tasks (Player x Season)\n",
                "targetPlayerIds = {} \n",
                "for season in seasons:\n",
                "    # print(f\"Fetching top scorers for {season}...\")\n",
                "    for p in getTopScorers(season, topNPlayers):\n",
                "        targetPlayerIds[p['PLAYER_ID']] = p['PLAYER_NAME']\n",
                "\n",
                "allTasks = []\n",
                "for pid, pname in targetPlayerIds.items():\n",
                "    for season in seasons:\n",
                "        allTasks.append((str(pid), pname, str(season)))\n",
                "\n",
                "# B. Read Completed Progress \n",
                "processedTasks = set()\n",
                "if os.path.exists(gamesCsvPath):\n",
                "    try:\n",
                "        # Force read as string to avoid int/float mismatch\n",
                "        dfExist = pd.read_csv(gamesCsvPath, usecols=['Player_ID', 'Season'], dtype=str, low_memory=False)\n",
                "        if not dfExist.empty:\n",
                "            for _, row in dfExist.iterrows():\n",
                "                # Handle formatted strings like '201939.0'\n",
                "                pidClean = str(row['Player_ID']).split('.')[0].strip()\n",
                "                seasonClean = str(row['Season']).strip()\n",
                "                processedTasks.add((pidClean, seasonClean))\n",
                "        print(f\"üîÑ Locked {len(processedTasks)} completed tasks (Skipping automatically)\")\n",
                "    except Exception as e:\n",
                "        print(f\"‚ö†Ô∏è Error reading old file (checking again): {e}\")\n",
                "\n",
                "# C. Filter Remaining Tasks\n",
                "tasksToRun = [t for t in allTasks if (str(t[0]), str(t[2])) not in processedTasks]\n",
                "print(f\"üöÄ Total Tasks: {len(allTasks)} | Pending: {len(tasksToRun)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "ee450d30",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "üéâ All tasks completed! Proceeding to cleanup.\n"
                    ]
                }
            ],
            "source": [
                "# ==========================================\n",
                "# 4. Execute Crawler\n",
                "# ==========================================\n",
                "\n",
                "if not tasksToRun:\n",
                "    print(\"üéâ All tasks completed! Proceeding to cleanup.\")\n",
                "else:\n",
                "    # dynamic_ncols=True adapts to window width\n",
                "    with tqdm(total=len(tasksToRun), desc=\"Initializing\", dynamic_ncols=True, unit=\"task\") as pbar:\n",
                "        \n",
                "        for pid, pName, season in tasksToRun:\n",
                "            # Double Check\n",
                "            if (str(pid), str(season)) in processedTasks:\n",
                "                pbar.update(1); continue\n",
                "\n",
                "            pbar.set_description(f\"Fetching: {pName} ({season})\")\n",
                "            \n",
                "            batchGames = []\n",
                "            batchShots = []\n",
                "\n",
                "            # --- A. Fetch Base Stats ---\n",
                "            baseApi = fetchWithRetry(playergamelog.PlayerGameLog, player_id=pid, season=season)\n",
                "            if not baseApi: \n",
                "                pbar.update(1); continue\n",
                "            dfBase = baseApi.get_data_frames()[0]\n",
                "            if dfBase.empty: \n",
                "                pbar.update(1); continue\n",
                "\n",
                "            # --- B. Fetch Advanced Stats & Merge ---\n",
                "            advApi = fetchWithRetry(\n",
                "                playergamelogs.PlayerGameLogs, \n",
                "                player_id_nullable=pid, season_nullable=season,\n",
                "                measure_type_player_game_logs_nullable='Advanced'\n",
                "            )\n",
                "            dfMerged = dfBase\n",
                "            if advApi:\n",
                "                dfAdv = advApi.get_data_frames()[0]\n",
                "                if not dfAdv.empty:\n",
                "                    dfBase['Game_ID'] = dfBase['Game_ID'].astype(str)\n",
                "                    dfAdv['GAME_ID'] = dfAdv['GAME_ID'].astype(str)\n",
                "                    \n",
                "                    advCols = ['GAME_ID', 'OFF_RATING', 'DEF_RATING', 'NET_RATING', 'AST_PCT', 'AST_TO', \n",
                "                                'OREB_PCT', 'TM_TOV_PCT', 'EFG_PCT', 'TS_PCT', 'USG_PCT', 'PACE', 'PIE']\n",
                "                    validCols = [c for c in advCols if c in dfAdv.columns]\n",
                "                    # Merge Base & Advanced\n",
                "                    dfMerged = pd.merge(dfBase, dfAdv[validCols], left_on='Game_ID', right_on='GAME_ID', how='left')\n",
                "\n",
                "            # --- C. Clean & Label Generation ---\n",
                "            try: dfMerged['GAME_DATE'] = pd.to_datetime(dfMerged['GAME_DATE'])\n",
                "            except: pass\n",
                "            \n",
                "            dfMerged = dfMerged.sort_values('GAME_DATE').reset_index(drop=True)\n",
                "            dfMerged['TARGET_PTS'] = dfMerged['PTS'].shift(-1) # Next Game Points\n",
                "            dfMerged['Player_ID'] = pid\n",
                "            dfMerged['Player_Name'] = pName\n",
                "            dfMerged['Season'] = season\n",
                "            dfMerged = dfMerged.dropna(subset=['TARGET_PTS']) # Remove last game (no label)\n",
                "            batchGames.append(dfMerged)\n",
                "\n",
                "            # --- D. Fetch Shot Charts ---\n",
                "            shotApi = fetchWithRetry(\n",
                "                shotchartdetail.ShotChartDetail,\n",
                "                team_id=0, player_id=pid, \n",
                "                context_measure_simple='FGA', season_nullable=season\n",
                "            )\n",
                "            if shotApi:\n",
                "                dfShots = shotApi.get_data_frames()[0]\n",
                "                if not dfShots.empty:\n",
                "                    sCols = ['GAME_ID', 'LOC_X', 'LOC_Y', 'SHOT_MADE_FLAG', 'SHOT_TYPE', 'ACTION_TYPE']\n",
                "                    validS = [c for c in sCols if c in dfShots.columns]\n",
                "                    batchShots.append(dfShots[validS])\n",
                "\n",
                "            # --- E. Incremental Save (Checkpoint) ---\n",
                "            if batchGames:\n",
                "                dfG = pd.concat(batchGames, ignore_index=True)\n",
                "                dfG.to_csv(gamesCsvPath, mode='a', header=not os.path.exists(gamesCsvPath), index=False)\n",
                "            \n",
                "            if batchShots:\n",
                "                dfS = pd.concat(batchShots, ignore_index=True)\n",
                "                dfS.to_csv(shotsCsvPath, mode='a', header=not os.path.exists(shotsCsvPath), index=False)\n",
                "\n",
                "            # Update Progress\n",
                "            processedTasks.add((str(pid), str(season)))\n",
                "            pbar.update(1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "3af64957",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "üèÅ Crawling Finished. Starting Final Cleanup...\n",
                        "‚úÖ Cleanup Complete: dataset\\games.csv        \n",
                        "‚úÖ Cleanup Complete: dataset\\shots.csv        \n",
                        "‚ú® All Done! Ready for model training.\n"
                    ]
                }
            ],
            "source": [
                "# ==========================================\n",
                "# 5. Final Cleanup & Deduplication\n",
                "# ==========================================\n",
                "print(\"\\nüèÅ Crawling Finished. Starting Final Cleanup...\")\n",
                "\n",
                "# Clean Game Data\n",
                "cleanDuplicates(gamesCsvPath, subsetCols=['Game_ID', 'Player_ID'])\n",
                "\n",
                "# Clean Shot Data\n",
                "cleanDuplicates(shotsCsvPath, subsetCols=['GAME_ID', 'LOC_X', 'LOC_Y', 'SHOT_TYPE'])\n",
                "\n",
                "print(\"‚ú® All Done! Ready for model training.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
